\documentclass{article}

% Pacchetti utili
\usepackage[utf8]{inputenc} % Per la codifica dei caratteri
\usepackage[T1]{fontenc} % Per i font
\usepackage{graphicx} % Per le immagini
\usepackage{amsmath, amssymb} % Per la matematica
\usepackage{hyperref} % Per i link
\usepackage{natbib} % Per le citazioni
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{amsfonts}


\begin{document}


Nei sistemi basati su \textit{feedback impliciti}, la mancanza di interazione tra un \textit{user} e un \textit{item} non implica necessariamente una preferenza negativa. Per affrontare tale ambiguità, BPR adotta le seguenti ipotesi:

\begin{itemize}
    \item Se $(u, i) \in R$, cioè lo \textit{user} $u$ ha interagito con l'\textit{item} $i$, allora $u$ preferisce $i$ a tutti gli \textit{item} $j$ con cui non ha interagito.
    \item A partire da questo principio, si costruisce un insieme di triple:
    \[
    D_S := \{(u, i, j) \mid i \in I_u \wedge j \in I \setminus I_u\}
    \]
    dove ogni tripla rappresenta la preferenza dello \textit{user} $u$ per l'\textit{item} $i$ rispetto all'\textit{item} $j$.
\end{itemize}

L'obiettivo di BPR è massimizzare la probabilità a posteriori dei parametri del modello $\Theta$, dati i dati osservati:
\[
\text{BPR-Opt} = \sum_{(u, i, j) \in D_S} \ln \sigma(\hat{x}_{uij}) - \lambda_\Theta ||\Theta||^2
\]
dove:
\begin{itemize}
    \item $\hat{x}_{uij} = \hat{x}_{ui} - \hat{x}_{uj}$ è la differenza tra le valutazioni stimate per $i$ e $j$;
    \item $\sigma(x) = \frac{1}{1 + e^{-x}}$ è la funzione sigmoide;
    \item $\lambda_\Theta$ è il parametro di regolarizzazione.
\end{itemize}

Questo criterio è strettamente legato all'ottimizzazione dell'AUC (Area Under the ROC Curve), che misura la qualità del ranking.

Per prima cosa si calcola il gradiente di BPR-Opt come:

\[
\frac{\partial \text{BPR-Opt}}{\partial \Theta} =
\sum_{(u,i,j) \in D_S} 
\frac{\partial}{\partial \Theta} \ln \sigma(\hat{x}_{uij}) - 
\lambda \frac{\partial}{\partial \Theta} ||\Theta||^2
\]

\[
\propto 
\sum_{(u,i,j) \in D_S} 
\frac{-e^{-\hat{x}_{uij}}}{1 + e^{-\hat{x}_{uij}}} 
\cdot \frac{\partial}{\partial \Theta} \hat{x}_{uij} 
- \lambda \Theta
\]

L'ottimizzazione di BPR-Opt viene effettuata tramite \textit{stochastic gradient descent}. I parametri del modello sono aggirnati con:

\[
\Theta \gets \Theta - \gamma \frac{\partial \text{BPR-Opt}}{\partial \Theta}
\]


L'algoritmo effettua un campionamento \textit{bootstrap}:

\begin{algorithm}[H]
\caption{LearnBPR}
\begin{algorithmic}[1]
\Procedure{LearnBPR}{$D_S, \Theta$}
    \State Inizializza $\Theta$
    \Repeat
        \State Campiona $(u, i, j)$ da $D_S$
        \State $\Theta \gets \Theta + \gamma \cdot \left( \frac{e^{-\hat{x}_{uij}}}{1 + e^{-\hat{x}_{uij}}} \cdot \frac{\partial \hat{x}_{uij}}{\partial \Theta} - \lambda_\Theta \cdot \Theta \right)$
    \Until{convergenza}
    \State \Return $\Theta$
\EndProcedure
\end{algorithmic}
\end{algorithm}

I parametri $\gamma$ e $\lambda$ sono iper-parametri dell'algoritmo.

Questo approccio consente una rapida convergenza e un buon bilanciamento tra classi positive e negative.

BPR può essere applicato a diverse famiglie di modelli. Di seguito viene presentata la versione con \textit{matrix factorization} (BPR-MF):

Ogni \textit{user} \( u \in U \) e ogni \textit{item} \( i \in I \) sono rappresentati da un vettore latente in \( \mathbb{R}^k \):

\[
\mathbf{w}_u \in \mathbb{R}^k \quad \text{(user)} \qquad
\mathbf{h}_i \in \mathbb{R}^k \quad \text{(item)}
\]


Per ogni tripla \( (u, i, j) \), il modello calcola:

\[
\hat{x}_{ui} = \langle \mathbf{w}_u, \mathbf{h}_i \rangle = \sum_{f=1}^{k} w_{uf} \cdot h_{if}
\]

\[
\hat{x}_{uj} = \langle \mathbf{w}_u, \mathbf{h}_j \rangle = \sum_{f=1}^{k} w_{uf} \cdot h_{jf}
\]

\[
\hat{x}_{uij} = \hat{x}_{ui} - \hat{x}_{uj} = \langle \mathbf{w}_u, \mathbf{h}_i - \mathbf{h}_j \rangle
\]


La funzione obiettivo da massimizzare è:

\[
\text{BPR-Opt} = \sum_{(u,i,j) \in D_S} \log \sigma(\hat{x}_{uij}) 
- \lambda \left( \|\mathbf{w}_u\|^2 + \|\mathbf{h}_i\|^2 + \|\mathbf{h}_j\|^2 \right)
\]

Definiamo:

\[
z = -\frac{\partial}{\partial \Theta} \ln \sigma(\hat{x}_{uij}) = \frac{e^{-\hat{x}_{uij}}}{1 + e^{-\hat{x}_{uij}}}
\]

Gli aggiornamenti dei parametri sono:

\begin{align*}
\mathbf{w}_u &\leftarrow \mathbf{w}_u + \gamma \left( z \cdot (\mathbf{h}_i - \mathbf{h}_j) - \lambda \cdot \mathbf{w}_u \right) \\
\mathbf{h}_i &\leftarrow \mathbf{h}_i + \gamma \left( z \cdot \mathbf{w}_u - \lambda \cdot \mathbf{h}_i \right) \\
\mathbf{h}_j &\leftarrow \mathbf{h}_j + \gamma \left( -z \cdot \mathbf{w}_u - \lambda \cdot \mathbf{h}_j \right)
\end{align*}


%TODO
Vantaggi

\begin{itemize}
    \item Ottimizza direttamente l'obiettivo di ranking anziché i rating.
    \item Si adatta bene a scenari con feedback impliciti.
    \item È flessibile e applicabile a vari modelli di raccomandazione.
    \item È empiricamente superiore a metodi classici come WR-MF e SVD.
\end{itemize}

La predizione viene dunque calcolata come:

\begin{itemize}
    \item \textbf{Ottimizzazione diretta per il ranking}  
    \begin{itemize}
        \item BPR è progettato specificamente per il ranking, a differenza di altri approcci come la regressione o la predizione esplicita delle valutazioni.
        \item Ottimizza la probabilità che un elemento positivo venga classificato sopra un elemento negativo.
    \end{itemize}
    
    \item \textbf{Approccio basato su coppie (pairwise)}
    \begin{itemize}
        \item BPR usa una loss basata su triplette \((u, i, j)\), dove l'elemento \(i\) è preferito rispetto a \(j\).
        \item Questo lo rende più efficace rispetto a metodi basati su errori quadratici (MSE) che non ottimizzano direttamente il ranking.
    \end{itemize}
    
    \item \textbf{Scalabilità}
    \begin{itemize}
        \item Può essere implementato in modo efficiente utilizzando \textit{stochastic gradient descent} (SGD).
        \item Grazie alla campionatura negativa può gestire dataset di grandi dimensioni.
    \end{itemize}
    
    \item \textbf{Generalizzabile}
    \begin{itemize}
        \item Può essere usato con diversi modelli di fattorizzazione della matrice, come \textit{Matrix Factorization} (MF) e \textit{Neural Collaborative Filtering} (NCF).
        \item Può essere esteso con modelli più complessi (es. convoluzioni, RNN, GNN).
    \end{itemize}
    
    \item \textbf{Non richiede esplicite valutazioni}
    \begin{itemize}
        \item Funziona bene anche in contesti con \textit{feedback implicito} (es. clic, acquisti, interazioni) senza bisogno di valutazioni numeriche.
    \end{itemize}
\end{itemize}

L'algoritmo soffre anche di diverse problematiche:

\begin{itemize}
    \item \textbf{Campionamento negativo non ottimale}
    \begin{itemize}
        \item La scelta di item negativi (cioè \(j\)) può influenzare molto la convergenza.
        \item Se il \textit{negative sampling} non è ben calibrato, il modello può imparare pattern non significativi.
        \item Una strategia di campionamento più avanzata (es. \textit{hard negative mining}) può essere necessaria.
    \end{itemize}
    
    \item \textbf{Problemi di convergenza}
    \begin{itemize}
        \item Converge lentamente rispetto ad altri metodi, specialmente in dataset molto \textit{sparsificati}.
        \item Richiede una buona calibrazione dei parametri (es. learning rate, regolarizzazione).
    \end{itemize}
    
    \item \textbf{Sensibile all'overfitting}
    \begin{itemize}
        \item La mancanza di regolarizzazione adeguata può portare a overfitting.
        \item I termini di regolarizzazione devono essere scelti con attenzione.
    \end{itemize}
    
    \item \textbf{Non modella relazioni globali tra gli item}
    \begin{itemize}
        \item BPR si basa su confronti locali tra coppie di item, senza sfruttare informazioni globali.
        \item Approcci basati su grafi o deep learning possono essere più efficaci nel catturare strutture complesse.
    \end{itemize}
    
    \item \textbf{Difficile da interpretare}
    \begin{itemize}
        \item A differenza di modelli più semplici (es. modelli basati su regole), BPR non fornisce spiegazioni dirette sulle raccomandazioni.
    \end{itemize}
\end{itemize}




\bibliographystyle{plain}
\bibliography{../bibliography}

\end{document}
